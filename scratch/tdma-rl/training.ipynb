{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import gym\n",
    "import argparse\n",
    "import numpy as np\n",
    "from ns3gym import ns3env\n",
    "from DQN_model import DeepQNetwork\n",
    "from DQN_model import Eval_Model\n",
    "from DQN_model import Target_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "reward_decay = 0.9\n",
    "e_greedy = 0.9\n",
    "replace_target_iter = 300\n",
    "memory_size = 500\n",
    "batch_size = 32\n",
    "episodes = 1500\n",
    "max_chosen = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got new port for ns3gm interface:  9526\n",
      "Observation space:  Dict(pktBytes:Box(4,), slotUsedTable:Box(100,)) None\n",
      "Action space:  Box(100,) int64\n",
      "n_action:  100\n"
     ]
    }
   ],
   "source": [
    "port = 0\n",
    "simTime = 20 # seconds\n",
    "stepTime = 0.5  # seconds\n",
    "seed = 0\n",
    "simArgs = {\"--simTime\": simTime,\n",
    "           \"--testArg\": 123}\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('ns3-v0')\n",
    "#env = ns3env.Ns3Env(debug=True)\n",
    "\n",
    "#env.reset()\n",
    "\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n",
    "ob_space_n = ob_space['slotUsedTable'].shape[0] + ob_space['pktBytes'].shape[0] - 1\n",
    "\n",
    "print(\"Observation space: \", ob_space,  ob_space.dtype)\n",
    "print(\"Action space: \", ac_space, ac_space.dtype)\n",
    "print(\"n_action: \",ac_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = Eval_Model(num_actions=ac_space.shape[0])\n",
    "target_model = Target_Model(num_actions=ac_space.shape[0])\n",
    "RL = DeepQNetwork(ac_space.shape[0], max_chosen, ob_space_n,\n",
    "                  eval_model, target_model, learning_rate, reward_decay, e_greedy, \n",
    "                  replace_target_iter, memory_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got new port for ns3gm interface:  6669\n",
      "---action:  [35 32 99]\n",
      "Step:  1\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 1\n",
      "---action:  [92  6  8]\n",
      "Step:  2\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 2\n",
      "---action:  [11 92  8]\n",
      "Step:  3\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 3\n",
      "---action:  [73  8 92]\n",
      "Step:  4\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 4\n",
      "---action:  [74 55 92]\n",
      "Step:  5\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 5\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "---action:  [74 87 92]\n",
      "Step:  6\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 6\n",
      "---action:  [ 8  6 92]\n",
      "Step:  7\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 7\n",
      "---action:  [87 74 92]\n",
      "Step:  8\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 8\n",
      "---action:  [87 74 92]\n",
      "Step:  9\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 9\n",
      "---action:  [87 55 92]\n",
      "Step:  10\n",
      "---obs, reward, done, info:  ([0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0], [0]) 0.0 False 10\n"
     ]
    }
   ],
   "source": [
    "for episode in range(1):\n",
    "    stepIdx = 0\n",
    "\n",
    "    _obs = env.reset()\n",
    "    \n",
    "    _obs = np.array(list(_obs[0]) + list(_obs[1][1:]))\n",
    "    _obs = np.pad(_obs,(0, ob_space_n - _obs.size), constant_values = 0)\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        stepIdx += 1\n",
    "\n",
    "        action = np.array(RL.choose_action(_obs))\n",
    "        \n",
    "        #action2 = env.action_space.sample()\n",
    "        \n",
    "        print(\"---action: \", action)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        print(\"Step: \", stepIdx)\n",
    "        print(\"---obs, reward, done, info: \", obs, reward, done, info)\n",
    "        \n",
    "        obs = np.array(list(obs[0]) + list(obs[1][1:]))\n",
    "        obs = np.pad(obs,(0, ob_space_n - obs.size), constant_values = 0)\n",
    "        \n",
    "        for act in action:\n",
    "            RL.store_transition(_obs, act, reward, obs)\n",
    "            \n",
    "        #RL.store_transition(_obs, action, reward, obs)\n",
    "        \n",
    "        if (stepIdx > 64*50) and (stepIdx % 5 == 0):\n",
    "            RL.learn()\n",
    "            \n",
    "        # swap observation\n",
    "        _obs = obs\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        #break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
